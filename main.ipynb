{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09dd652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import NNConv, BatchNorm, global_mean_pool, MessagePassing\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU, BatchNorm1d, Dropout\n",
    "from torch_geometric.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97995245-dc1f-4e56-a776-2c5d085db654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import robotic as ry\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15e56315-19c5-4bb9-894b-c1cb252d8ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEdgeConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='max')  # \"Max\" aggregation.\n",
    "        self.mlp = Seq(Linear(2 * in_channels + 3, out_channels), ReLU(), Linear(out_channels, out_channels))\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        return self.propagate(edge_index, x=x, edge_weight=edge_weight)\n",
    "    def message(self, x_i, x_j, edge_weight):\n",
    "        tmp = torch.cat([x_i, x_j - x_i, edge_weight.view(-1, 3)], dim=1)\n",
    "        return self.mlp(tmp)\n",
    "\n",
    "class GNNModel(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GNNModel, self).__init__()\n",
    "        self.conv1 = CustomEdgeConv(in_channels, hidden_channels)\n",
    "        self.bn1 = BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = CustomEdgeConv(hidden_channels, hidden_channels)\n",
    "        self.bn2 = BatchNorm1d(hidden_channels)\n",
    "        self.conv3 = CustomEdgeConv(hidden_channels, hidden_channels)  # Additional Conv layer\n",
    "        self.bn3 = BatchNorm1d(hidden_channels)\n",
    "        self.conv4 = CustomEdgeConv(hidden_channels, hidden_channels)  # Additional Conv layer\n",
    "        self.bn4 = BatchNorm1d(hidden_channels)\n",
    "        self.conv5 = CustomEdgeConv(hidden_channels, hidden_channels)  # Additional Conv layer\n",
    "        #self.bn5 = BatchNorm1d(hidden_channels)\n",
    "        self.conv6 = CustomEdgeConv(hidden_channels, hidden_channels)  # Additional Conv layer\n",
    "        #self.dropout = Dropout(p=0.5)  # Dropout layer\n",
    "        self.out = torch.nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = F.leaky_relu(x, negative_slope=0.2)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        x = F.leaky_relu(x, negative_slope=0.2)\n",
    "        x = self.conv3(x, edge_index, edge_attr)\n",
    "        x = F.leaky_relu(x, negative_slope=0.2)\n",
    "        x = self.conv4(x, edge_index, edge_attr)\n",
    "        x = F.leaky_relu(x, negative_slope=0.2)\n",
    "        x = F.leaky_relu(x, negative_slope=0.2)\n",
    "        x = self.conv6(x, edge_index, edge_attr)\n",
    "        #x = self.dropout(x)  # Applying dropout\n",
    "        x = F.sigmoid(self.out(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d995651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_g_file(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        content = file.read()\n",
    "    return content\n",
    "\n",
    "def get_relative_position(G, start_node, end_node):\n",
    "    try:\n",
    "        edge_data = G.get_edge_data(start_node, end_node)\n",
    "        if edge_data is not None:\n",
    "            relative_pos = edge_data['weight']\n",
    "            return relative_pos\n",
    "        else:\n",
    "            print(\"No direct edge between these nodes.\")\n",
    "            return None\n",
    "    except KeyError:\n",
    "        print(\"One or both of the nodes do not exist in the graph.\")\n",
    "        return None\n",
    "\n",
    "def parse_transform(transform_string):\n",
    "    translation_match = re.search(r't\\((.*?)\\)', transform_string)\n",
    "    if translation_match:\n",
    "        translation_values = translation_match.group(1)\n",
    "        return np.array([float(val) for val in translation_values.split()])\n",
    "    return np.zeros(3)\n",
    "\n",
    "position_pattern = re.compile(r'object(\\d+).*?X:\\s*\\[([^\\]]+)\\]')\n",
    "transform_pattern = re.compile(r'object(\\d+)\\(object(\\d+)\\).*?Q:\\s*\"([^\"]+)\"')\n",
    "\n",
    "def process_g_file(filepath):\n",
    "    g_content = read_g_file(filepath)\n",
    "\n",
    "    object_positions = {}\n",
    "    object_transformations = {}\n",
    "\n",
    "    for line in g_content.split('\\n'):\n",
    "        if line.strip() == \"\":\n",
    "            continue\n",
    "\n",
    "        position_match = position_pattern.match(line)\n",
    "        if position_match:\n",
    "            obj_id = int(position_match.group(1)) - 1\n",
    "            position = np.array([float(n) for n in position_match.group(2).split(', ')[:3]])\n",
    "            object_positions[obj_id] = position\n",
    "\n",
    "        transform_match = transform_pattern.match(line)\n",
    "        if transform_match:\n",
    "            obj_id = int(transform_match.group(1)) - 1\n",
    "            base_obj_id = int(transform_match.group(2)) - 1\n",
    "            transform_string = transform_match.group(3)\n",
    "            transformation = parse_transform(transform_string)\n",
    "            object_transformations[obj_id] = (base_obj_id, transformation)\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Update positions with transformations\n",
    "    for obj_id, (base_obj_id, transformation) in object_transformations.items():\n",
    "        if base_obj_id in object_positions:\n",
    "            transformed_pos = object_positions[base_obj_id] + transformation\n",
    "            object_positions[obj_id] = transformed_pos\n",
    "\n",
    "    # Add edges considering the pair only once\n",
    "    for start_id, start_pos in object_positions.items():\n",
    "        for end_id, end_pos in object_positions.items():\n",
    "            if start_id < end_id:  # Ensures each pair is considered only once\n",
    "                relative_pos = end_pos - start_pos\n",
    "                if not G.has_edge(end_id, start_id) or not np.array_equal(-relative_pos, G[end_id][start_id]['weight']):\n",
    "                    G.add_edge(start_id, end_id, weight=relative_pos)\n",
    "    for (u, v, w) in list(G.edges(data='weight')):\n",
    "        if w[2] < 0:\n",
    "            G.remove_edge(u, v)\n",
    "            G.add_edge(v, u, weight=-w)\n",
    "    \n",
    "    return G, object_positions\n",
    "\n",
    "\n",
    "def process_all_g_files(directory):\n",
    "    all_graphs = []\n",
    "    all_positions = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.g'):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            G, positions = process_g_file(filepath)\n",
    "            all_graphs.append(G)\n",
    "            all_positions.append(positions)\n",
    "    return all_graphs, all_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d9bc694-dd75-466d-8fe6-13cb036135bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_pyg_data(graph):\n",
    "    node_features = torch.ones((graph.number_of_nodes(), 1))  # Assuming all nodes have a feature '1'\n",
    "    edge_index = torch.tensor(list(graph.edges), dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor([graph[u][v]['weight'] for u, v in graph.edges()], dtype=torch.float)\n",
    "    return Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr, y=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb358bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 1  \n",
    "hidden_channels = 32 \n",
    "out_channels = 1\n",
    "\n",
    "model = GNNModel(in_channels, hidden_channels, out_channels)\n",
    "\n",
    "model_path = 'last_model.pth'  # Update with your file path\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4477c0b1-4cd7-430c-bc5c-f45a0ab23947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 19\n",
      "Number of edges: 137\n",
      "tensor([0.5880, 0.5812, 0.6188, 0.6175, 0.5896, 0.6727, 0.6728, 0.6962, 0.5809,\n",
      "        0.6916, 0.7010, 0.6761, 0.6614, 0.6785, 0.6604, 0.6820, 0.6624, 0.6469,\n",
      "        0.5809])\n",
      "18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def correct_graph_edge_indices(graphs):\n",
    "    for graph in graphs:\n",
    "        corrected_edges_with_attrs = []\n",
    "        for u, v, attrs in graph.edges(data=True):\n",
    "            corrected_u = u - 1 if u > 0 else u\n",
    "            corrected_v = v - 1 if v > 0 else v\n",
    "            corrected_edges_with_attrs.append((corrected_u, corrected_v, attrs))\n",
    "        graph.clear_edges()\n",
    "        for u, v, attrs in corrected_edges_with_attrs:\n",
    "            graph.add_edge(u, v, **attrs)\n",
    "\n",
    "target_graph, pos = process_all_g_files('target')\n",
    "correct_graph_edge_indices(target_graph)\n",
    "target_pyg = [convert_to_pyg_data(graph) for graph, positions in zip(target_graph, pos)][0]\n",
    "test_data = target_pyg\n",
    "\n",
    "print(\"Number of nodes:\", test_data.num_nodes)\n",
    "print(\"Number of edges:\", test_data.num_edges)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    if test_data.num_nodes != 1:\n",
    "        prediction = model(test_data)\n",
    "        prediction = prediction.squeeze()  # Remove any extra dimensions\n",
    "        predicted_probs = torch.sigmoid(prediction)\n",
    "        print(predicted_probs)\n",
    "        preds = np.array(predicted_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a959810b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Order: [19, 18, 14, 13, 6, 0, 1, 2, 17, 16, 11, 7, 12, 10, 9, 8, 3, 15, 5, 4]\n"
     ]
    }
   ],
   "source": [
    "def run_inference_and_reduce_graph(target_folder):\n",
    "    target_graphs, positions = process_all_g_files(target_folder)\n",
    "    target_pyg = [convert_to_pyg_data(graph) for graph in target_graph][0]\n",
    "    original_indices = list(range(target_pyg.num_nodes))\n",
    "    removal_order = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        while target_pyg.num_nodes > 1:\n",
    "            prediction = model(target_pyg)\n",
    "            prediction = prediction.squeeze()\n",
    "            predicted_probs = torch.sigmoid(prediction)\n",
    "\n",
    "            max_prob_node = predicted_probs.argmax().item()\n",
    "            removal_order.append(original_indices[max_prob_node])\n",
    "            target_pyg = remove_node_and_edges(target_pyg, max_prob_node)\n",
    "            del original_indices[max_prob_node]\n",
    "        if target_pyg.num_nodes == 1:\n",
    "            remaining_node_original_index = original_indices[0]\n",
    "            removal_order.append(remaining_node_original_index)\n",
    "\n",
    "    return removal_order\n",
    "\n",
    "def remove_node_and_edges(data, node_idx):\n",
    "    # Create a mask for the nodes to keep\n",
    "    node_mask = torch.ones(data.num_nodes, dtype=torch.bool)\n",
    "    node_mask[node_idx] = False\n",
    "    data.x = data.x[node_mask]\n",
    "    edge_mask = (data.edge_index[0] != node_idx) & (data.edge_index[1] != node_idx)\n",
    "    data.edge_index = data.edge_index[:, edge_mask]\n",
    "    data.edge_index[0, data.edge_index[0] > node_idx] -= 1\n",
    "    data.edge_index[1, data.edge_index[1] > node_idx] -= 1\n",
    "    if data.edge_attr is not None:\n",
    "        data.edge_attr = data.edge_attr[edge_mask]\n",
    "    return data\n",
    "\n",
    "target_folder = 'target'\n",
    "removal_order = run_inference_and_reduce_graph(target_folder)\n",
    "building_order = removal_order[::-1]\n",
    "print(\"Building Order:\", building_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4901532c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_points(n, y_value, start_x):\n",
    "    points = [(round(start_x + i*1.2,2), y_value,0.4) for i in range(n)]\n",
    "    return np.array(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ff07033",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_list = start_points(len(building_order), -1.3, -3)\n",
    "pos_dict = {}\n",
    "for node_index, position in pos[0].items():\n",
    "    pos_dict[node_index] = [start_list[node_index], position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23f3b285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<robotic._robotic.Frame at 0x7ff2023847b0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = ry.Config()\n",
    "C.addFile(\"robot_free.g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bc56c471-730c-4149-8efa-edd67eb290ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = ry.Simulation(C, ry.SimulationEngine.physx, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b13f3ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in pos_dict:\n",
    "    name = \"object\"+str(obj)\n",
    "    target = \"target\"+str(obj)\n",
    "    pos = pos_dict[obj][0]\n",
    "    target_pos = pos_dict[obj][1]\n",
    "    C.addFrame(name).setShape(ry.ST.ssBox, [0.8, 0.8, 0.8, .01]).setColor([0.5,0.5,0.5]).setPosition(pos)\n",
    "    C.addFrame(target).setShape(ry.ST.marker, [.1]) .setPosition(target_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "17f7d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "qHome = C.getJointState()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ea872df1-27c5-4c0e-b885-22f8eeb16e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_objects = len(building_order)\n",
    "komo = ry.KOMO(C, 3*num_objects, 30, 1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e3b23440-dc97-4e6e-bd95-c18c3d9a52e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<robotic._robotic.KOMO_Objective at 0x7ff206e38770>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komo.addControlObjective([], 1, 1e0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "444c19f6-b695-4d75-bc2e-8d5eb6eab003",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in enumerate(building_order):\n",
    "    obj_name = \"object\"+str(j)\n",
    "    target_name = \"target\"+str(j)\n",
    "    komo.addObjective([float(3*i+1)], ry.FS.positionDiff, ['r_endeffector', obj_name], ry.OT.eq, [1e3],[0,0,0])\n",
    "    komo.addObjective([float(3*i+1)], ry.FS.jointState, [], ry.OT.eq, [1e1], [], order=1)\n",
    "    komo.addModeSwitch([float(3*i+2),float(3*i+3)], ry.SY.stable, ['r_endeffector', obj_name])\n",
    "    komo.addObjective([float(3*i+3)], ry.FS.positionDiff, [obj_name, target_name], ry.OT.eq, [1e2],[0,0,0])\n",
    "    komo.addObjective([float(3*i+3)], ry.FS.vectorZ, [obj_name], ry.OT.eq, [1e2], [0., 0., 0.])\n",
    "    komo.addObjective([float(3*i+3)], ry.FS.vectorX, [obj_name], ry.OT.eq, [1e2], [0., 0., 0.])\n",
    "    komo.addObjective([float(3*i+3)], ry.FS.vectorY, [obj_name], ry.OT.eq, [1e2], [0., 0., 0.])\n",
    "    komo.addObjective([float(3*i+3)], ry.FS.jointState, [], ry.OT.eq, [1e1], [], order=1)\n",
    "    komo.addModeSwitch([float(3*i+3),-1], ry.SY.stable, [target_name,obj_name])\n",
    "komo.addObjective([], ry.FS.accumulatedCollisions, [], ry.OT.eq,[1e1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c81c71a1-e257-4bba-974a-ab1a10b8ba7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ time: 0.22574, evals: 85, done: 1, feasible: 0, sos: 65.0934, f: 0, ineq: 0, eq: 1906.78 }\n",
      "size of path: (540, 7)\n"
     ]
    }
   ],
   "source": [
    "ret = ry.NLP_Solver(komo.nlp(), verbose=0 ).solve()\n",
    "print(ret)\n",
    "q = komo.getPath()\n",
    "print('size of path:', q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2e7096-9439-4102-bf9e-50f6dbc1fe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(q.shape[0]):\n",
    "    C.setJointState(q[t])\n",
    "    time.sleep(.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "260f5ad6-ac61-4c9b-b4ed-7a3561a98f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komo.view_play(True, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6d58f3f-fbf9-42c1-9e75-999bd0a05d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 23.3 from /home/lira-bot2024/miniconda3/lib/python3.11/site-packages/pip (python 3.11)\n"
     ]
    }
   ],
   "source": [
    "!pip --version robotic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6683a3-27b1-4377-954e-a3f419a3b7cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
