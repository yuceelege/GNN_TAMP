{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09dd652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import NNConv, BatchNorm, global_mean_pool, MessagePassing\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU, BatchNorm1d, Dropout\n",
    "from torch_geometric.data import DataLoader\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import robotic as ry\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97995245-dc1f-4e56-a776-2c5d085db654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03c0c3c5-90d9-4d51-9421-b2218259d6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C1 = ry.Config()\n",
    "# C1.addFile(\"target/sample_61.g\")\n",
    "# C1.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15e56315-19c5-4bb9-894b-c1cb252d8ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEdgeConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='mean')\n",
    "        self.mlp = Seq(Linear(2 * in_channels + 3, out_channels), ReLU(), Linear(out_channels, out_channels))\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        return self.propagate(edge_index, x=x, edge_weight=edge_weight)\n",
    "    def message(self, x_i, x_j, edge_weight):\n",
    "        tmp = torch.cat([x_i, x_j - x_i, edge_weight.view(-1, 3)], dim=1)\n",
    "        return self.mlp(tmp)\n",
    "\n",
    "class GNNModel(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GNNModel, self).__init__()\n",
    "        self.conv1 = CustomEdgeConv(in_channels, hidden_channels)\n",
    "        self.out = torch.nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = F.sigmoid(self.out(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d995651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_g_file(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        content = file.read()\n",
    "    return content\n",
    "\n",
    "def get_relative_position(G, start_node, end_node):\n",
    "    try:\n",
    "        edge_data = G.get_edge_data(start_node, end_node)\n",
    "        if edge_data is not None:\n",
    "            relative_pos = edge_data['weight']\n",
    "            return relative_pos\n",
    "        else:\n",
    "            print(\"No direct edge between these nodes.\")\n",
    "            return None\n",
    "    except KeyError:\n",
    "        print(\"One or both of the nodes do not exist in the graph.\")\n",
    "        return None\n",
    "\n",
    "def parse_transform(transform_string):\n",
    "    translation_match = re.search(r't\\((.*?)\\)', transform_string)\n",
    "    if translation_match:\n",
    "        translation_values = translation_match.group(1)\n",
    "        return np.array([float(val) for val in translation_values.split()])\n",
    "    return np.zeros(3)\n",
    "\n",
    "# Precompile regular expressions\n",
    "position_pattern = re.compile(r'object(\\d+).*?X:\\s*\\[([^\\]]+)\\]')\n",
    "transform_pattern = re.compile(r'object(\\d+)\\(object(\\d+)\\).*?Q:\\s*\"([^\"]+)\"')\n",
    "\n",
    "def process_g_file(filepath):\n",
    "    g_content = read_g_file(filepath)\n",
    "\n",
    "    object_positions = {}\n",
    "    object_transformations = {}\n",
    "\n",
    "    for line in g_content.split('\\n'):\n",
    "        if line.strip() == \"\":\n",
    "            continue\n",
    "\n",
    "        position_match = position_pattern.match(line)\n",
    "        if position_match:\n",
    "            obj_id = int(position_match.group(1)) - 1\n",
    "            position = np.array([float(n) for n in position_match.group(2).split(', ')[:3]])\n",
    "            object_positions[obj_id] = position\n",
    "\n",
    "        transform_match = transform_pattern.match(line)\n",
    "        if transform_match:\n",
    "            obj_id = int(transform_match.group(1)) - 1\n",
    "            base_obj_id = int(transform_match.group(2)) - 1\n",
    "            transform_string = transform_match.group(3)\n",
    "            transformation = parse_transform(transform_string)\n",
    "            object_transformations[obj_id] = (base_obj_id, transformation)\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Update positions with transformations\n",
    "    for obj_id, (base_obj_id, transformation) in object_transformations.items():\n",
    "        if base_obj_id in object_positions:\n",
    "            transformed_pos = object_positions[base_obj_id] + transformation\n",
    "            object_positions[obj_id] = transformed_pos\n",
    "\n",
    "    # Add edges considering the pair only once\n",
    "    for start_id, start_pos in object_positions.items():\n",
    "        for end_id, end_pos in object_positions.items():\n",
    "            if start_id < end_id:  # Ensures each pair is considered only once\n",
    "                relative_pos = end_pos - start_pos\n",
    "                if not G.has_edge(end_id, start_id) or not np.array_equal(-relative_pos, G[end_id][start_id]['weight']):\n",
    "                    G.add_edge(start_id, end_id, weight=relative_pos)\n",
    "    for (u, v, w) in list(G.edges(data='weight')):\n",
    "        if w[2] < 0:\n",
    "            G.remove_edge(u, v)\n",
    "            G.add_edge(v, u, weight=-w)\n",
    "    \n",
    "    return G, object_positions\n",
    "\n",
    "\n",
    "def process_all_g_files(directory):\n",
    "    all_graphs = []\n",
    "    all_positions = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.g'):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            G, positions = process_g_file(filepath)\n",
    "            all_graphs.append(G)\n",
    "            all_positions.append(positions)\n",
    "    return all_graphs, all_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d9bc694-dd75-466d-8fe6-13cb036135bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_pyg_data(graph):\n",
    "    # Using a constant feature (1) for all nodes\n",
    "    node_features = torch.ones((graph.number_of_nodes(), 1))  # Assuming all nodes have a feature '1'\n",
    "\n",
    "    # Convert edge indices and edge attributes\n",
    "    edge_index = torch.tensor(list(graph.edges), dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor([graph[u][v]['weight'] for u, v in graph.edges()], dtype=torch.float)\n",
    "\n",
    "    # Node labels\n",
    "    #y = torch.tensor([data for _, data in graph.nodes(data='label')], dtype=torch.float)\n",
    "\n",
    "    return Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr, y=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7460b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f68e5e-1e85-4586-9004-bcb24bd498a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4431b2-90ef-48d0-a4c0-64cbc6eeee85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75a58d30-43a4-4a1e-9fd5-34c18a3e252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = 65\n",
    "\n",
    "# # Find the index of the maximum prediction value\n",
    "# max_index = np.argmax(preds)\n",
    "\n",
    "# path = \"target/\"  # path to the data\n",
    "# new_path = \"target2/\"  # path to the new data\n",
    "\n",
    "# filename = path + \"wall_\" + str(a) + \".g\"\n",
    "# new_filename = new_path + \"wall_\" + str(a) + \".g\"\n",
    "# with open(filename, 'r') as f:\n",
    "#     data = f.read()\n",
    "#     data = data.split('\\n')\n",
    "#     data = data[:-1]\n",
    "\n",
    "#     with open(new_filename, 'w') as f_new:\n",
    "#         for j, line in enumerate(data):\n",
    "#             if j == max_index:\n",
    "#                 new_color = \"color: [0, 1, 0]\"  # Green for the maximum prediction\n",
    "#                 print(j)\n",
    "#             else:\n",
    "#                 new_color = \"color: [0.5, 0.5, 0.5]\"  # Gray for all other lines\n",
    "\n",
    "#             # Replace the existing color line with the new color line\n",
    "#             new_line = line.replace(\"color: [0.5, 0.5, 0.5]\", new_color)\n",
    "#             f_new.write(new_line + \"\\n\")\n",
    "\n",
    "# # The rest of your code remains the same\n",
    "# C = ry.Config()\n",
    "# C.addFile(new_filename)  # Use the modified filename\n",
    "# C.view()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4477c0b1-4cd7-430c-bc5c-f45a0ab23947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 10\n",
      "Number of edges: 37\n",
      "tensor([0.5012, 0.5009, 0.5043, 0.7241, 0.6315, 0.5987, 0.7229, 0.6806, 0.6958,\n",
      "        0.6241])\n",
      "[0.00133372 0.         0.01522196 1.         0.58510137 0.43812105\n",
      " 0.99445313 0.80492234 0.8729764  0.55177325]\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_channels = 1  \n",
    "hidden_channels = 32 \n",
    "out_channels = 1\n",
    "\n",
    "model = GNNModel(in_channels, hidden_channels, out_channels)\n",
    "\n",
    "model_path = 'last_model1.pth'  # Update with your file path\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "def correct_graph_edge_indices(graphs):\n",
    "    for graph in graphs:\n",
    "        corrected_edges_with_attrs = []\n",
    "\n",
    "        # Store edges with corrected indices and their attributes\n",
    "        for u, v, attrs in graph.edges(data=True):\n",
    "            corrected_u = u - 1 if u > 0 else u\n",
    "            corrected_v = v - 1 if v > 0 else v\n",
    "            corrected_edges_with_attrs.append((corrected_u, corrected_v, attrs))\n",
    "\n",
    "        # Clear existing edges and re-add them with original attributes\n",
    "        graph.clear_edges()\n",
    "        for u, v, attrs in corrected_edges_with_attrs:\n",
    "            graph.add_edge(u, v, **attrs)\n",
    "\n",
    "\n",
    "# Convert labeled graphs to PyTorch Geometric format\n",
    "target_graph, pos = process_all_g_files('obje')\n",
    "\n",
    "correct_graph_edge_indices(target_graph)\n",
    "\n",
    "target_pyg = [convert_to_pyg_data(graph) for graph, positions in zip(target_graph, pos)][0]\n",
    "test_data = target_pyg\n",
    "\n",
    "# Print the shape/details of the test data\n",
    "print(\"Number of nodes:\", test_data.num_nodes)\n",
    "print(\"Number of edges:\", test_data.num_edges)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    if test_data.num_nodes != 1:\n",
    "        prediction = model(test_data)\n",
    "        prediction = prediction.squeeze()  # Remove any extra dimensions\n",
    "        predicted_probs = torch.sigmoid(prediction)\n",
    "        print(predicted_probs)\n",
    "        preds = np.array(predicted_probs)\n",
    "\n",
    "a = 1\n",
    "\n",
    "# min-max normalization\n",
    "preds = (preds - min(preds)) / (max(preds) - min(preds))\n",
    "print(preds)\n",
    "path = \"obje/\" # path to the data\n",
    "new_path = \"target2/\" # path to the new data\n",
    "\n",
    "filename = path + \"sample_\" + str(a) + \".g\"\n",
    "new_filename = new_path + \"sample_\" + str(a) + \".g\"\n",
    "with open(filename, 'r') as f:\n",
    "    data = f.read()\n",
    "    data = data.split('\\n')\n",
    "    data = data[:-1]\n",
    "    print(len(data))\n",
    "    with open(new_filename, 'w') as f:\n",
    "        for j in range(len(data)):\n",
    "            body, color = data[j].split('color: ')\n",
    "            new_color = \"[\" + str(1 - preds[j]) + \", \" + str(preds[j]) + \", \" + str(0) + \"]}\"\n",
    "            new_data = body + \"color: \" + new_color\n",
    "\n",
    "            f.write(new_data + \"\\n\")\n",
    "C = ry.Config()\n",
    "C.addFile(\"target2/sample_{}.g\".format(str(a)))\n",
    "C.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d03832e-be6f-402c-84e3-0cac5430b8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch_geometric.data.data.Data"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e787c50a-b886-4757-b060-6d7a3cb082fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: array([-0.0389, -0.035 ,  0.4   ]),\n",
       "  1: array([-0.0763,  0.9696,  0.4   ]),\n",
       "  2: array([0.0469, 2.05  , 0.4   ]),\n",
       "  3: array([-0.0278,  3.0582,  0.4   ]),\n",
       "  4: array([-0.0331,  0.3552,  1.2   ]),\n",
       "  5: array([0.0769, 1.4769, 1.2   ]),\n",
       "  6: array([0.0509, 2.6067, 1.2   ]),\n",
       "  8: array([-1.50e-03, -6.15e-02,  2.00e+00]),\n",
       "  9: array([0.0309, 1.0114, 2.    ]),\n",
       "  10: array([0.0395, 2.0778, 2.    ]),\n",
       "  11: array([-0.0313,  3.0029,  2.    ]),\n",
       "  12: array([-0.0036,  0.4598,  2.8   ]),\n",
       "  13: array([0.06  , 1.4757, 2.8   ]),\n",
       "  14: array([0.0303, 2.6119, 2.8   ]),\n",
       "  16: array([0.0238, 0.0281, 3.6   ]),\n",
       "  17: array([-0.0613,  0.9754,  3.6   ]),\n",
       "  18: array([-0.0589,  2.0588,  3.6   ]),\n",
       "  19: array([-0.0224,  3.0521,  3.6   ])}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a959810b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Order: [0, 1, 5, 3, 2, 4]\n"
     ]
    }
   ],
   "source": [
    "def run_inference_and_reduce_graph(target_folder):\n",
    "    target_graphs, positions = process_all_g_files(target_folder)\n",
    "    target_pyg = [convert_to_pyg_data(graph) for graph in target_graph][0]\n",
    "    original_indices = list(range(target_pyg.num_nodes))\n",
    "    removal_order = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        while target_pyg.num_nodes > 1:\n",
    "            prediction = model(target_pyg)\n",
    "            prediction = prediction.squeeze()\n",
    "            predicted_probs = torch.sigmoid(prediction)\n",
    "\n",
    "            max_prob_node = predicted_probs.argmax().item()\n",
    "            removal_order.append(original_indices[max_prob_node])\n",
    "            target_pyg = remove_node_and_edges(target_pyg, max_prob_node)\n",
    "            del original_indices[max_prob_node]\n",
    "        if target_pyg.num_nodes == 1:\n",
    "            remaining_node_original_index = original_indices[0]\n",
    "            removal_order.append(remaining_node_original_index)\n",
    "\n",
    "    return removal_order\n",
    "\n",
    "def remove_node_and_edges(data, node_idx):\n",
    "    # Create a mask for the nodes to keep\n",
    "    node_mask = torch.ones(data.num_nodes, dtype=torch.bool)\n",
    "    node_mask[node_idx] = False\n",
    "    data.x = data.x[node_mask]\n",
    "    edge_mask = (data.edge_index[0] != node_idx) & (data.edge_index[1] != node_idx)\n",
    "    data.edge_index = data.edge_index[:, edge_mask]\n",
    "    data.edge_index[0, data.edge_index[0] > node_idx] -= 1\n",
    "    data.edge_index[1, data.edge_index[1] > node_idx] -= 1\n",
    "    if data.edge_attr is not None:\n",
    "        data.edge_attr = data.edge_attr[edge_mask]\n",
    "    return data\n",
    "\n",
    "target_folder = 'target'\n",
    "removal_order = run_inference_and_reduce_graph(target_folder)\n",
    "building_order = removal_order[::-1]\n",
    "print(\"Building Order:\", building_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c4abd79-fa95-49a8-be10-05c3f21b5b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "building_order = [0,1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68253126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4901532c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_points(n, y_value, start_x):\n",
    "    points = [(round(start_x + i*1.2,2), y_value,0.4) for i in range(n)]\n",
    "    return np.array(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ff07033",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_list = start_points(len(building_order), -1.3, -3)\n",
    "pos_dict = {}\n",
    "for node_index, position in pos[0].items():\n",
    "    pos_dict[node_index] = [start_list[node_index], position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23f3b285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<robotic._robotic.Frame at 0x7ff2023847b0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = ry.Config()\n",
    "C.addFile(\"robot_free.g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bc56c471-730c-4149-8efa-edd67eb290ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = ry.Simulation(C, ry.SimulationEngine.physx, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9583867f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [array([-3. , -1.3,  0.4]), array([-1.2,  0. ,  0.4])], 1: [array([-1.8, -1.3,  0.4]), array([-0.302,  0.   ,  0.4  ])], 2: [array([-0.6, -1.3,  0.4]), array([0.526, 0.   , 0.4  ])], 3: [array([ 0.6, -1.3,  0.4]), array([-0.8,  0. ,  1.2])], 4: [array([ 1.8, -1.3,  0.4]), array([0.034, 0.   , 1.2  ])], 5: [array([ 3. , -1.3,  0.4]), array([-0.2,  0. ,  2. ])]}\n"
     ]
    }
   ],
   "source": [
    "print(pos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca371190-a8cb-4ae1-bb2c-c44460b099f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b13f3ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in pos_dict:\n",
    "    name = \"object\"+str(obj)\n",
    "    target = \"target\"+str(obj)\n",
    "    pos = pos_dict[obj][0]\n",
    "    target_pos = pos_dict[obj][1]\n",
    "    C.addFrame(name).setShape(ry.ST.ssBox, [0.8, 0.8, 0.8, .01]).setColor([0.5,0.5,0.5]).setPosition(pos)\n",
    "    C.addFrame(target).setShape(ry.ST.marker, [.1]) .setPosition(target_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "17f7d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "qHome = C.getJointState()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1e5988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ea872df1-27c5-4c0e-b885-22f8eeb16e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_objects = len(building_order)\n",
    "komo = ry.KOMO(C, 3*num_objects, 30, 1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e3b23440-dc97-4e6e-bd95-c18c3d9a52e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<robotic._robotic.KOMO_Objective at 0x7ff206e38770>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komo.addControlObjective([], 1, 1e0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "444c19f6-b695-4d75-bc2e-8d5eb6eab003",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in enumerate(building_order):\n",
    "    obj_name = \"object\"+str(j)\n",
    "    target_name = \"target\"+str(j)\n",
    "    komo.addObjective([float(3*i+1)], ry.FS.positionDiff, ['r_endeffector', obj_name], ry.OT.eq, [1e3],[0,0,0])\n",
    "    komo.addObjective([float(3*i+1)], ry.FS.jointState, [], ry.OT.eq, [1e1], [], order=1)\n",
    "    komo.addModeSwitch([float(3*i+2),float(3*i+3)], ry.SY.stable, ['r_endeffector', obj_name])\n",
    "    komo.addObjective([float(3*i+3)], ry.FS.positionDiff, [obj_name, target_name], ry.OT.eq, [1e2],[0,0,0])\n",
    "    komo.addObjective([float(3*i+3)], ry.FS.vectorZ, [obj_name], ry.OT.eq, [1e2], [0., 0., 0.])\n",
    "    komo.addObjective([float(3*i+3)], ry.FS.vectorX, [obj_name], ry.OT.eq, [1e2], [0., 0., 0.])\n",
    "    komo.addObjective([float(3*i+3)], ry.FS.vectorY, [obj_name], ry.OT.eq, [1e2], [0., 0., 0.])\n",
    "    komo.addObjective([float(3*i+3)], ry.FS.jointState, [], ry.OT.eq, [1e1], [], order=1)\n",
    "    komo.addModeSwitch([float(3*i+3),-1], ry.SY.stable, [target_name,obj_name])\n",
    "komo.addObjective([], ry.FS.accumulatedCollisions, [], ry.OT.eq,[1e1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c81c71a1-e257-4bba-974a-ab1a10b8ba7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ time: 0.22574, evals: 85, done: 1, feasible: 0, sos: 65.0934, f: 0, ineq: 0, eq: 1906.78 }\n",
      "size of path: (540, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ret = ry.NLP_Solver(komo.nlp(), verbose=0 ).solve()\n",
    "print(ret)\n",
    "q = komo.getPath()\n",
    "print('size of path:', q.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2e7096-9439-4102-bf9e-50f6dbc1fe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(q.shape[0]):\n",
    "    C.setJointState(q[t])\n",
    "    S.step([], 0.1,  ry.ControlMode.none)\n",
    "    time.sleep(.1)\n",
    "    C.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "260f5ad6-ac61-4c9b-b4ed-7a3561a98f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komo.view_play(True, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6d58f3f-fbf9-42c1-9e75-999bd0a05d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 23.3 from /home/lira-bot2024/miniconda3/lib/python3.11/site-packages/pip (python 3.11)\n"
     ]
    }
   ],
   "source": [
    "!pip --version robotic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6683a3-27b1-4377-954e-a3f419a3b7cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
